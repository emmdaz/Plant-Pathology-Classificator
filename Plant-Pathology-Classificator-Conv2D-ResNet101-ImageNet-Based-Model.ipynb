{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDDD-PreTrain\n",
    "\n",
    "#### Based i the pre-trained model revised in https://doi.org/10.34133/plantphenomics.0054\n",
    "Xinyu Dong, Qi Wang, Qianding Huang, Qinglong Ge, Kejun Zhao ,Xingcai Wu, Xue Wu, Liang Lei, Gefei Hao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU \\n\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/workspace/Optuna-Trials/Plant-Pathology-Classificator-Conv2D-Trials\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos \n",
    "\n",
    "df = pd.read_csv(\"/tf/Plant-Pathology-Classificator/plant-pathology-2020-/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df[\"label\"] = df[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].idxmax(axis=1)\n",
    "\n",
    "df[\"filepath\"] = df['image_id'].apply(lambda x: os.path.join(\"/tf/Plant-Pathology-Classificator/plant-pathology-2020-/images\", f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size = 0.5, stratify = df[\"label\"], random_state = 4)\n",
    "\n",
    "X_test, X_val = train_test_split(X_temp, test_size = 0.4, stratify = X_temp[\"label\"], random_state = 4)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_saturation_filter(img):\n",
    "    \n",
    "    # Convertir a uint8\n",
    "    if img.dtype == np.float32 and img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    # Convertir RGB a HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Rangos de matiz\n",
    "    red_mask1 = (h < 10)\n",
    "    red_mask2 = (h > 170)\n",
    "    orange_yellow_mask = (h >= 10) & (h <= 30)\n",
    "    green_mask = (h >= 35) & (h <= 85)\n",
    "    cyan_blue_mask = (h >= 90) & (h <= 130)\n",
    "\n",
    "    # Saturar rojo, naranja y amarillo\n",
    "    s[red_mask1 | red_mask2 | orange_yellow_mask] *= 3.0\n",
    "\n",
    "    # Disminuir tonos azules\n",
    "    s[cyan_blue_mask] *= 0.7\n",
    "    \n",
    "    # Disminuir saturación del verde\n",
    "    s[green_mask] *= 0.7   \n",
    "\n",
    "    # Disminuir luminancia del verde\n",
    "    v[green_mask] *= 0.85 \n",
    "\n",
    "    # Recortar valores a [0,255]\n",
    "    s = np.clip(s, 0, 255)\n",
    "    v = np.clip(v, 0, 255)\n",
    "\n",
    "    # Juntar y convertir en RGB\n",
    "    hsv_mod = cv2.merge([h, s, v]).astype(np.uint8)\n",
    "    rgb_mod = cv2.cvtColor(hsv_mod, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    return rgb_mod.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessing(img):\n",
    "\n",
    "    img = color_saturation_filter(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "    preprocessing_function = custom_preprocessing,\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 0.01 ,          \n",
    "    width_shift_range = 0.02,      \n",
    "    height_shift_range = 0.02,     \n",
    "    shear_range = 0.2,            \n",
    "    horizontal_flip = True,       \n",
    "    vertical_flip = True,         \n",
    "    brightness_range = (1.0, 1.12),\n",
    "    channel_shift_range = 30.0,\n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "datagen_test_and_val = ImageDataGenerator(rescale = 1./255,\n",
    "                                          preprocessing_function = custom_preprocessing,\n",
    "                                          dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datagen_train.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    seed = 4,\n",
    ")\n",
    "\n",
    "test = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False,\n",
    "    seed = 4\n",
    ")\n",
    "\n",
    "val = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = X_val,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    shuffle = False,  \n",
    "    seed = 4\n",
    ")\n",
    "\n",
    "mini_train = datagen_train.flow_from_dataframe(\n",
    "    dataframe = mini_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    seed = 4\n",
    ")\n",
    "\n",
    "mini_val = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = mini_val,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False,\n",
    "    seed = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(train)\n",
    "\n",
    "label_indices = np.argmax(labels, axis=1)\n",
    "class_names = list(train.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.title(class_names[label_indices[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "img, labels = next(mini_train)\n",
    "\n",
    "label_indices = np.argmax(labels, axis=1)\n",
    "class_names = list(mini_train.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.title(class_names[label_indices[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(val)\n",
    "\n",
    "label_indices = np.argmax(labels, axis=1)\n",
    "class_names = list(val.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.title(class_names[label_indices[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "img, labels = next(mini_val)\n",
    "\n",
    "label_indices = np.argmax(labels, axis=1)\n",
    "class_names = list(mini_val.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.title(class_names[label_indices[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet101(pretrained=False)\n",
    "\n",
    "num_classes = 20\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "state_dict = torch.load(\"/tf/Plant-Pathology-Classificator/ResNet_101_ImageNet_plant-model-84.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.fc = torch.nn.Identity() # Borrar última capa para exportar únicamente el extractor de características\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Conversión a .onnx\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"features\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"features\": {0: \"batch\"}},\n",
    ")\n",
    "\n",
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "\n",
    "def convert_model_to_fp32(model_path, output_path):\n",
    "    model = onnx.load(model_path)\n",
    "\n",
    "    for tensor in list(model.graph.initializer):\n",
    "        arr = numpy_helper.to_array(tensor)\n",
    "        if arr.dtype == \"float16\":\n",
    "            print(f\"Converting initializer {tensor.name} from float16 → float32\")\n",
    "            new_tensor = numpy_helper.from_array(arr.astype(\"float32\"), name=tensor.name)\n",
    "            model.graph.initializer.remove(tensor)\n",
    "            model.graph.initializer.append(new_tensor)\n",
    "\n",
    "    for value_info in list(model.graph.input) + list(model.graph.output):\n",
    "        ttype = value_info.type.tensor_type\n",
    "        if ttype.elem_type == 10:  # float16\n",
    "            ttype.elem_type = 1     # float32\n",
    "\n",
    "    for node in model.graph.node:\n",
    "        for attr in node.attribute:\n",
    "\n",
    "            if hasattr(attr, \"t\") and attr.t.data_type == 10:\n",
    "                arr = numpy_helper.to_array(attr.t).astype(\"float32\")\n",
    "                attr.t.CopyFrom(numpy_helper.from_array(arr))\n",
    "\n",
    "            if hasattr(attr, \"tensors\"):\n",
    "                for t in attr.tensors:\n",
    "                    if t.data_type == 10:\n",
    "                        arr = numpy_helper.to_array(t).astype(\"float32\")\n",
    "                        t.CopyFrom(numpy_helper.from_array(arr))\n",
    "\n",
    "    onnx.save(model, output_path)\n",
    "\n",
    "convert_model_to_fp32(\"model.onnx\", \"model_all_fp32.onnx\")\n",
    "\n",
    "model_check = onnx.load(\"model_all_fp32.onnx\")\n",
    "float16_tensors = []\n",
    "for t in model_check.graph.initializer:\n",
    "    if numpy_helper.to_array(t).dtype == \"float16\":\n",
    "        float16_tensors.append(t.name)\n",
    "\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"model_all_fp32.onnx\")\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(\"ResNet101_ImageNet_TF\")\n",
    "print(\"Finalizó conversión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tf.saved_model.load(\"ResNet101_ImageNet_TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Model\n",
    "base = tf.saved_model.load(\"ResNet101_ImageNet_TF\")  # or your path\n",
    "resnet_fn = base.signatures[\"serving_default\"]\n",
    "\n",
    "# Wrapper layer\n",
    "    class ResNet101_Pretrained(tf.keras.layers.Layer):\n",
    "        def __init__(self, resnet_fn):\n",
    "            super().__init__()\n",
    "            self.resnet_fn = resnet_fn\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # NHWC → NCHW\n",
    "        x = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        \n",
    "        if not self._trainable:\n",
    "            with tf.GradientTape(stop_recording = True):\n",
    "                outputs = self.resnet_fn(input = x)\n",
    "        else:\n",
    "            outputs = self.resnet_fn(input = x)\n",
    "            \n",
    "        features = list(outputs.values())[0]\n",
    "        features = tf.ensure_shape(features, [None, 2048])\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Firs, the model will be checked using a color saturation filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4 \n",
    "\n",
    "inputs = tf.keras.Input(shape = (224, 224, 3))\n",
    "x = ResNet101_Pretrained(resnet_fn)(inputs)\n",
    "x = layers.Dense(512, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(512, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 10, restore_best_weights = True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project = \"Plant-Pathology-Classificator-Conv2D-ResNet101-ImageNet-Based-Model.ipynb-Series-1\",\n",
    "    name = \"Trial_1_with_filter\",\n",
    "    reinit = True,\n",
    "    config = {\n",
    "            \"Input_Layer\": (224,224,3),\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"Pretrained model\": \"ResNet101 \",\n",
    "            \"optimizer\": \"RMSprop\",\n",
    "            \"loss\" : \"Categorical CrossEntropy\"\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(train,\n",
    "                    validation_data = val,\n",
    "                    epochs = 200,\n",
    "                    callbaacks = [WandbMetricsLogger(log_freq = 5), early_stopping, lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Plant-Pathology-Classificator-Conv2D-ResNet101-ImageNet-Based-Model-Filter.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, the model will be checked without the color saturation filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train2 = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 0.01 ,          \n",
    "    width_shift_range = 0.02,      \n",
    "    height_shift_range = 0.02,     \n",
    "    shear_range = 0.2,            \n",
    "    horizontal_flip = True,       \n",
    "    vertical_flip = True,         \n",
    "    brightness_range = (1.0, 1.12),\n",
    "    channel_shift_range = 30.0,\n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "datagen_test_and_val2 = ImageDataGenerator(rescale = 1./255,\n",
    "                                          dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datagen_train2.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    seed = 4,\n",
    ")\n",
    "\n",
    "test = datagen_test_and_val2.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False,\n",
    "    seed = 4\n",
    ")\n",
    "\n",
    "val = datagen_test_and_val2.flow_from_dataframe(\n",
    "    dataframe = X_val,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    shuffle = False,  \n",
    "    seed = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4  \n",
    "\n",
    "inputs = tf.keras.Input(shape = (224, 224, 3))\n",
    "x = TorchResNetWrapper(resnet_fn)(inputs)\n",
    "x = layers.Dense(512, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(512, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project = \"Plant-Pathology-Classificator-Conv2D-ResNet101-ImageNet-Based-Model.ipynb-Series-1\",\n",
    "    name = \"Trial_1_without_filter\",\n",
    "    reinit = True,\n",
    "    config = {\n",
    "            \"Input_Layer\": (224,224,3),\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"Pretrained model\": \"ResNet101 \",\n",
    "            \"optimizer\": \"RMSprop\",\n",
    "            \"loss\" : \"Categorical CrossEntropy\"\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(train,\n",
    "                    validation_data = val,\n",
    "                    epochs = 200,\n",
    "                    callbaacks = [WandbMetricsLogger(log_freq = 5), early_stopping, lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Plant-Pathology-Classificator-Conv2D-ResNet101-ImageNet-Based-Model-without-Filter.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
