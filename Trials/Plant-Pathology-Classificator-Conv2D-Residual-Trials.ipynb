{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU \n",
      " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU \\n\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is a no-op as it is now the default behavior.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmdaz\u001b[0m (\u001b[33memmdaz-zzz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de los datos \n",
    "\n",
    "df = pd.read_csv(\"/Plant-Pathology-Classificator/plant-pathology-2020-/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# convert one-hot columns to a single class name\n",
    "df[\"label\"] = df[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].idxmax(axis=1)\n",
    "\n",
    "df[\"filepath\"] = df['image_id'].apply(lambda x: os.path.join(\"/Plant-Pathology-Classificator/plant-pathology-2020-/images\", f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1274\n",
      "Test size: 364\n",
      "Validation size: 183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size = 0.3, stratify = df[\"label\"], random_state = 4)\n",
    "\n",
    "X_test, X_val = train_test_split(X_temp, test_size = 1/3, stratify = X_temp[\"label\"], random_state = 4)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n",
    "print(\"Validation size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small training size: 254\n",
      "Small training size: 91\n"
     ]
    }
   ],
   "source": [
    "mini_train, _ = train_test_split(X_train, test_size = 0.8, stratify = X_train[\"label\"], random_state = 4)\n",
    "\n",
    "mini_test, _ = train_test_split(X_test, test_size = 0.75, stratify = X_test[\"label\"], random_state = 4)\n",
    "\n",
    "print(\"Small training size:\", len(mini_train))\n",
    "print(\"Small training size:\", len(mini_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1274 validated image filenames belonging to 4 classes.\n",
      "Found 364 validated image filenames belonging to 4 classes.\n",
      "Found 183 validated image filenames belonging to 4 classes.\n",
      "Found 254 validated image filenames belonging to 4 classes.\n",
      "Found 91 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train = datagen.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "test = datagen.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "val = datagen.flow_from_dataframe(\n",
    "    dataframe = X_val,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "mini_train = train = datagen.flow_from_dataframe(\n",
    "    dataframe = mini_train,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "mini_test = train = datagen.flow_from_dataframe(\n",
    "    dataframe = mini_test,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128, 128),\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = models.Sequential()\n",
    "    inputs = layers.Input(shape=(128, 128, 3))\n",
    "    \n",
    "    # Optuna sugiere número de kernels y su tamaño en la primer capa convolucional,\n",
    "    # así como su función de activación\n",
    "    \n",
    "    kernel_1 = trial.suggest_int(\"Kernel_1\", 10, 64)\n",
    "    size_1 = trial.suggest_categorical(\"Kernel_Size_1\", [3,7,8,10])\n",
    "    activation_1 = trial.suggest_categorical(\"Activation_1\", [\"relu\", \"relu6\", \"selu\", \"leaky_relu\", \"relu6\"])\n",
    "    \n",
    "    # Primera convolución\n",
    "    x = layers.Conv2D(kernel_1, (size_1,size_1), padding = \"same\")(inputs)\n",
    "    x = layers.Activation(activation_1)(x)\n",
    "    \n",
    "    # Función para los bloques residuales\n",
    "    def residual_block(x, kernel, kernel_size, activation, dropout, dropout_rate, regularizer, r_1, r_2):\n",
    "        \n",
    "        residual = x  \n",
    "\n",
    "        # Camino \"principal\"\n",
    "        \n",
    "        if regularizer == \"L1\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              activation = activation, kernel_regularizer = regularizers.L1(r_1))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            \n",
    "        elif regularizer == \"L2\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              activation = activation, kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            \n",
    "        elif regularizer == \"L1L2\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              activation = activation, kernel_regularizer = regularizers.L1L2(r_1,r_2))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\", activation = activation)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Capa intermedia Dropout                      \n",
    "        if dropout == \"y\":\n",
    "            \n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "        # Segunda capa Convolicional, lineal\n",
    "        if regularizer == \"L1\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              kernel_regularizer = regularizers.L1(r_1))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            \n",
    "        elif regularizer == \"L2\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\", \n",
    "                              kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            \n",
    "        elif regularizer == \"L1L2\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              kernel_regularizer = regularizers.L1L2(r_1, r_2))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Suma de la conexión residual\n",
    "        x = layers.add([x, residual]) # Capa que suma elemento a elemento\n",
    "        x = layers.Activation(activation)(x)\n",
    "        return x\n",
    "    \n",
    "    # Optuna sugiere regularizador\n",
    "    regularizer = trial.suggest_categorical(\"Regularizer\", [\"L1\",\"L2\",\"L1L2\"])\n",
    "    r_1 = trial.suggest_float(\"regularizer_value\", 1e-6, 1e-4, log = True)\n",
    "    r_2 = trial.suggest_float(\"regularizer_value_2\", 1e-6, 1e-4, log = True)\n",
    "    \n",
    "    # Primer bloque residual\n",
    "                              \n",
    "    x = residual_block(x, kernel_1, size_1, activation_1, \"n\", 0.0, regularizer, r_1, r_2)\n",
    "    \n",
    "    kernel_per_layer = [kernel_1]\n",
    "    kernel_size_per_layer = [size_1]\n",
    "    activation_per_layer = [activation_1]\n",
    "    \n",
    "    # Optuna sugiere número de capas, número de kernels su tamaño y función de activación; también sugiere Dropout\n",
    "    # y regularizadores\n",
    "                              \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 10, 50)\n",
    "    \n",
    "    dropout_per_layer = []\n",
    "    dropout_percentage_per_layer = []\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        kernel = trial.suggest_int(f\"Kernel_{i+2}\", 10, 64)\n",
    "        kernel_per_layer.append(kernel)\n",
    "        \n",
    "        kernel_size = trial.suggest_categorical(f\"Kernel_Size_{i+2}\", [3,7,8,10])\n",
    "        kernel_size_per_layer.append(kernel_size)\n",
    "            \n",
    "        activation = trial.suggest_categorical(f\"Activation_{i+2}\", [\"relu\", \"relu6\", \"selu\", \"leaky_relu\", \"relu6\"])      \n",
    "        activation_per_layer.append(activation)\n",
    "                              \n",
    "        dropout = trial.suggest_categorical(f\"Dropout_L{i+2}\", [\"y\", \"n\"])\n",
    "        dropout_per_layer.append(dropout)\n",
    "                              \n",
    "        dropout_rate = trial.suggest_float(f\"Dropout_value_L{i+2}\",0.2, 0.5)\n",
    "        \n",
    "        if dropout == \"y\":\n",
    "            dropout_percentage_per_layer.append(dropout_rate)\n",
    "        else:\n",
    "            dropout_percentage_per_layer.append(0.0)\n",
    "        \n",
    "        # Capa Convolucional i-ésima\n",
    "        if regularizer == \"L1\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), strides = 2, padding = \"same\", activation = activation,\n",
    "                          kernel_regularizer = regularizers.L1(r_1))(x)\n",
    "        elif regularizer == \"L2\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), strides = 2, padding = \"same\", activation = activation,\n",
    "                          kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "        else: \n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), strides = 2, padding = \"same\", activation = activation,\n",
    "                          kernel_regularizer = regularizers.L1L2(r_1,r_2))(x)\n",
    "    \n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Bloque residual i-ésimo\n",
    "        x = residual_block(x, kernel, kernel_size, activation, dropout, dropout_rate, regularizer, r_1, r_2)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "                              \n",
    "    outputs = layers.Dense(4, activation = \"softmax\")(x)\n",
    "\n",
    "    # Optuna sugiere Learning Rate y Optimizador\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "                              \n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "                              \n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "        \n",
    "        \n",
    "    model = models.Model(inputs, outputs)\n",
    "                              \n",
    "    model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "\n",
    "    wandb.init(\n",
    "        project = \"Plant-Pathology-Classificator-Conv2D-Residual-Trials\",\n",
    "        name = f\"Trial_{trial.number}\",\n",
    "        reinit = True,\n",
    "        config = {\n",
    "            \"n_layers\": n_layers,\n",
    "            \"kernel_per_layer\": kernel_per_layer,\n",
    "            \"kernel_size_per_layer\": kernel_size_per_layer,\n",
    "            \"activations_per_layer\": activation_per_layer,\n",
    "            \"regularizer\": regularizer,\n",
    "            \"r_value\": r_1,\n",
    "            \"r_value2\": r_2,\n",
    "            \"dropout_per_layer\": dropout_per_layer,\n",
    "            \"dropout_percentage_per_layer\": dropout_percentage_per_layer,\n",
    "            \"learning_rate\": lr,\n",
    "            \"optimizer\": optimizer_name\n",
    "        }\n",
    "    )\n",
    "                              \n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 8, restore_best_weights = True)\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            mini_train, validation_data = mini_test,\n",
    "            epochs = 100,\n",
    "            batch_size = 16,\n",
    "            verbose = 0, \n",
    "            callbacks = [WandbMetricsLogger(log_freq=5), early_stopping]\n",
    "        )\n",
    "\n",
    "        val_loss = min(history.history[\"val_loss\"])\n",
    "        train_loss = min(history.history[\"loss\"])\n",
    "    \n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        tf.keras.backend.clear_session()\n",
    "        wandb.finish()\n",
    "        return float(\"inf\")\n",
    "\n",
    "    # Penalize overfitting\n",
    "    score = val_loss + 0.1 * (train_loss - val_loss)\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    wandb.finish()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 00:45:26,717] A new study created in memory with name: Proyecto\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Plant-Pathology-Classificator/Trials/wandb/run-20251107_004528-2c3xxkfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials/runs/2c3xxkfp' target=\"_blank\">Trial_0</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials/runs/2c3xxkfp' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials/runs/2c3xxkfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-07 00:47:26,738] Trial 0 failed with parameters: {'Kernel_1': 27, 'Kernel_Size_1': 3, 'Activation_1': 'relu', 'Regularizer': 'L1L2', 'regularizer_value': 7.76538450712258e-06, 'regularizer_value_2': 3.3757807612369066e-06, 'n_layers': 13, 'Kernel_2': 19, 'Kernel_Size_2': 3, 'Activation_2': 'relu6', 'Dropout_L2': 'y', 'Dropout_value_L2': 0.45892864642850156, 'Kernel_3': 30, 'Kernel_Size_3': 8, 'Activation_3': 'leaky_relu', 'Dropout_L3': 'y', 'Dropout_value_L3': 0.39931364383399354, 'Kernel_4': 27, 'Kernel_Size_4': 8, 'Activation_4': 'selu', 'Dropout_L4': 'n', 'Dropout_value_L4': 0.4769718726781105, 'Kernel_5': 36, 'Kernel_Size_5': 7, 'Activation_5': 'selu', 'Dropout_L5': 'y', 'Dropout_value_L5': 0.36866456171585477, 'Kernel_6': 44, 'Kernel_Size_6': 3, 'Activation_6': 'relu', 'Dropout_L6': 'y', 'Dropout_value_L6': 0.3436035246625151, 'Kernel_7': 46, 'Kernel_Size_7': 3, 'Activation_7': 'selu', 'Dropout_L7': 'n', 'Dropout_value_L7': 0.41279840095294085, 'Kernel_8': 40, 'Kernel_Size_8': 10, 'Activation_8': 'selu', 'Dropout_L8': 'n', 'Dropout_value_L8': 0.4674744148478774, 'Kernel_9': 22, 'Kernel_Size_9': 8, 'Activation_9': 'relu6', 'Dropout_L9': 'y', 'Dropout_value_L9': 0.24370427067287537, 'Kernel_10': 59, 'Kernel_Size_10': 10, 'Activation_10': 'leaky_relu', 'Dropout_L10': 'n', 'Dropout_value_L10': 0.30988605805539354, 'Kernel_11': 24, 'Kernel_Size_11': 10, 'Activation_11': 'selu', 'Dropout_L11': 'y', 'Dropout_value_L11': 0.40431535284107123, 'Kernel_12': 23, 'Kernel_Size_12': 7, 'Activation_12': 'relu6', 'Dropout_L12': 'y', 'Dropout_value_L12': 0.4723262048922553, 'Kernel_13': 27, 'Kernel_Size_13': 3, 'Activation_13': 'relu6', 'Dropout_L13': 'y', 'Dropout_value_L13': 0.3558609249574535, 'Kernel_14': 27, 'Kernel_Size_14': 8, 'Activation_14': 'relu', 'Dropout_L14': 'y', 'Dropout_value_L14': 0.3064434213983609, 'learning_rate': 0.00028383955032654066, 'optimizer': 'sgd'} because of the following error: NameError(\"name 'gc' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-10-d539ad44ff29>\", line 197, in objective\n",
      "    gc.collect()\n",
      "NameError: name 'gc' is not defined\n",
      "[W 2025-11-07 00:47:26,739] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProyecto\u001b[39m\u001b[38;5;124m\"\u001b[39m, direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [10], line 197\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    194\u001b[0m score \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m (train_loss \u001b[38;5;241m-\u001b[39m val_loss)\n\u001b[1;32m    196\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m--> 197\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    198\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name = \"Proyecto\", direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de pruebas terminadas: \", len(study.trials))\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Mejor intento: \", trial)\n",
    "\n",
    "print(\"Valor: \", trial.value)\n",
    "print(\"Hiperparámetros: \", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
