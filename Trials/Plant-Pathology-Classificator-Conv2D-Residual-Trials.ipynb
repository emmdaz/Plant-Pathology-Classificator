{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU \n",
      " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU \\n\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is a no-op as it is now the default behavior.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de los datos \n",
    "\n",
    "df = pd.read_csv(\"/Plant-Pathology-Classificator/plant-pathology-2020-/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df[\"label\"] = df[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].idxmax(axis=1)\n",
    "\n",
    "df[\"filepath\"] = df['image_id'].apply(lambda x: os.path.join(\"/Plant-Pathology-Classificator/plant-pathology-2020-/images\", f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1274\n",
      "Test size: 364\n",
      "Validation size: 183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size = 0.3, stratify = df[\"label\"], random_state = 4)\n",
    "\n",
    "X_test, X_val = train_test_split(X_temp, test_size = 1/3, stratify = X_temp[\"label\"], random_state = 4)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n",
    "print(\"Validation size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small training size: 382\n",
      "Small test size: 182\n"
     ]
    }
   ],
   "source": [
    "mini_train, _ = train_test_split(X_train, test_size = 0.7, stratify = X_train[\"label\"], random_state = 4)\n",
    "\n",
    "mini_test, _ = train_test_split(X_test, test_size = 0.5, stratify = X_test[\"label\"], random_state = 4)\n",
    "\n",
    "print(\"Small training size:\", len(mini_train))\n",
    "print(\"Small test size:\", len(mini_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "    rotation_range = 0.1,\n",
    "    brightness_range = (0.25,1.5),\n",
    "    channel_shift_range = 20.0,\n",
    "    fill_mode = \"nearest\",\n",
    "    cval = 128,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    rescale=1./255,\n",
    "    dtype = \"float32\"\n",
    "    )\n",
    "\n",
    "datagen_test_and_val = ImageDataGenerator(rescale=1./255, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1274 validated image filenames belonging to 4 classes.\n",
      "Found 364 validated image filenames belonging to 4 classes.\n",
      "Found 183 validated image filenames belonging to 4 classes.\n",
      "Found 382 validated image filenames belonging to 4 classes.\n",
      "Found 182 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train = datagen_train.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128,128),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "test = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    image_size = (128,128),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "val = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = X_val,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128,128),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "mini_train = train = datagen_train.flow_from_dataframe(\n",
    "    dataframe = mini_train,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128,128),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "mini_test = train = datagen_test_and_val.flow_from_dataframe(\n",
    "    dataframe = mini_test,\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'label',\n",
    "    image_size = (128,128),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para los bloques residuales\n",
    "\n",
    "def residual_block(x, kernel, kernel_size, activation, dropout, dropout_rate, regularizer, r_2):\n",
    "        \n",
    "    residual = x  \n",
    "        \n",
    "    if dropout == \"y\":\n",
    "        # Camino \"principal\"\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                              activation = activation)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "            \n",
    "        # Capa lineal\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "            \n",
    "    else: \n",
    "        # Camino \"principal\"\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                                  activation = activation, kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "                \n",
    "        # Capa lineal\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                                  kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "            \n",
    "    if x.shape[-1] != residual.shape[-1]:\n",
    "        residual = layers.Conv2D(filters = kernel, kernel_size = (1, 1), padding = \"same\")(residual)\n",
    "        residual = layers.BatchNormalization()(residual)\n",
    "\n",
    "    # Suma de la conexión residual\n",
    "    x = layers.add([x, residual]) \n",
    "    x = layers.Activation(activation)(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1650, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = models.Sequential()\n",
    "    inputs = layers.Input(shape=(128, 128, 3))\n",
    "    # x = data_augmentation(inputs, training = True)\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    # Optuna sugiere función de activación para todas las capas\n",
    "    activation = \"relu6\"\n",
    "    \n",
    "    # Optuna sugiere regularizador\n",
    "    regularizer = \"L2\"\n",
    "    r_2 = trial.suggest_float(\"regularizer_value_2\", 1e-6, 3e-6, log = True)\n",
    "    \n",
    "    # Optuna sugiere el número de capas\n",
    "    n_layers = 20\n",
    "    \n",
    "    # Optuna sugiere número de kernels y su tamaño en la primer capa convolucional\n",
    "    \n",
    "    kernel_1 = trial.suggest_int(\"Kernel_1\", 10, 16)\n",
    "    size_1 = trial.suggest_categorical(\"Kernel_Size_1\", [2,7])\n",
    "    \n",
    "    # Optuna sugiere Learning Rate y Optimizador\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", 2.5e-4, 1e-3, log = True)\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"rms\", \"rmsprop\"])\n",
    "    \n",
    "                              \n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "                              \n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    # Primera convolución\n",
    "    x = layers.Conv2D(kernel_1, (size_1,size_1), padding = \"same\")(inputs)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    \n",
    "    # Primer bloque residual\n",
    "                              \n",
    "    x = residual_block(x, kernel_1, size_1, activation, \"n\", 0.0, regularizer, r_2)\n",
    "    \n",
    "    kernel_per_layer = [kernel_1]\n",
    "    kernel_size_per_layer = [size_1]\n",
    "    \n",
    "    # Optuna sugiere número de kernels su tamaño y función de activación; también sugiere Dropout\n",
    "    # y regularizadores\n",
    "    \n",
    "    dropout_per_layer = []\n",
    "    dropout_percentage_per_layer = []\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        kernel = trial.suggest_int(f\"Kernel_{i+2}\", 32, 64)\n",
    "        kernel_per_layer.append(kernel)\n",
    "        \n",
    "        kernel_size = trial.suggest_categorical(f\"Kernel_Size_{i+2}\", [3,5])\n",
    "        kernel_size_per_layer.append(kernel_size)    \n",
    "                              \n",
    "        dropout = trial.suggest_categorical(f\"Dropout_L{i+2}\", [\"y\", \"n\"])\n",
    "        dropout_per_layer.append(dropout)\n",
    "                              \n",
    "        dropout_rate = trial.suggest_float(f\"Dropout_value_L{i+2}\",0.1, 0.2)\n",
    "        \n",
    "        # Capa Convolucional i-ésima:\n",
    "        \n",
    "        # Se elige entre Dropout o un Regularizador\n",
    "        if dropout == \"y\":\n",
    "            dropout_percentage_per_layer.append(dropout_rate)\n",
    "        else:\n",
    "            dropout_percentage_per_layer.append(0.0)\n",
    "        \n",
    "        if dropout == \"n\":\n",
    "            x = layers.Conv2D(kernel, (kernel_size, kernel_size), strides = 2, padding = \"same\",\n",
    "                              activation = activation, kernel_regularizer = regularizers.L2(r_2))(x)\n",
    "    \n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Bloque residual i-ésimo:\n",
    "        x = residual_block(x, kernel, kernel_size, activation, dropout, dropout_rate, regularizer, r_2)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "                              \n",
    "    outputs = layers.Dense(4, activation = \"softmax\")(x)\n",
    "        \n",
    "    model = models.Model(inputs, outputs)\n",
    "                              \n",
    "    model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "    \n",
    "    #############################################################################################################\n",
    "\n",
    "    wandb.init(\n",
    "        project = \"Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0\",\n",
    "        name = f\"Trial_{trial.number}\",\n",
    "        reinit = True,\n",
    "        config = {\n",
    "            \"kernel_1\": kernel_1,\n",
    "            \"size_1\": size_1,\n",
    "            \"activation\": activation,\n",
    "            \"n_layers\": n_layers,\n",
    "            \"kernel_per_layer\": kernel_per_layer,\n",
    "            \"kernel_size_per_layer\": kernel_size_per_layer,\n",
    "            \"regularizer\": regularizer,\n",
    "            \"r_value2\": r_2,\n",
    "            \"dropout_per_layer\": dropout_per_layer,\n",
    "            \"dropout_percentage_per_layer\": dropout_percentage_per_layer,\n",
    "            \"learning_rate\": lr,\n",
    "            \"optimizer\": optimizer_name,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #############################################################################################################\n",
    "                              \n",
    "    early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "    # lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor = 0.5, patience = 5)\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            mini_train,\n",
    "            validation_data = mini_test,\n",
    "            epochs = 200,\n",
    "            batch_size = 32,\n",
    "            verbose = 1, \n",
    "            callbacks = [WandbMetricsLogger(log_freq = 5), early_stopping]\n",
    "        )\n",
    "\n",
    "        # val_loss = min(history.history[\"val_loss\"])\n",
    "        # train_loss = min(history.history[\"loss\"])\n",
    "        val_accuracy = max(history.history[\"val_accuracy\"])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Intento falló debido a: {e}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        wandb.finish()\n",
    "        gc.collect()\n",
    "        return float(\"inf\")\n",
    "\n",
    "    # Penalize overfitting\n",
    "    \n",
    "    # score = val_loss + 0.1 * (train_loss - val_loss)\n",
    "    \n",
    "    score = val_accuracy\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    wandb.finish()\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 06:14:58,156] A new study created in memory with name: Experimentos-Serie-2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/Plant-Pathology-Classificator/Trials/wandb/run-20251108_061509-kncc7tnj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0/runs/kncc7tnj' target=\"_blank\">Trial_0</a></strong> to <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0/runs/kncc7tnj' target=\"_blank\">https://wandb.ai/emmdaz-zzz/Plant-Pathology-Classificator-Conv2D-Residual-Trials-4.0/runs/kncc7tnj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name = \"Experimentos-Serie-2.0\", direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Número de pruebas terminadas: \", len(study.trials))\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Mejor intento: \", trial)\n",
    "\n",
    "print(\"Valor: \", trial.value)\n",
    "print(\"Hiperparámetros: \", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
